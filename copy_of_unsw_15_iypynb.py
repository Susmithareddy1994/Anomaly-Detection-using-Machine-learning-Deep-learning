# -*- coding: utf-8 -*-
"""Copy of UNSW-15.iypynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1m7pDiINqUMHSscRT9WUCvKPEQtCjm_nn
"""

import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn import preprocessing
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score
from sklearn.metrics import classification_report,confusion_matrix
from sklearn import svm
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split

"""Data Import"""

# Test Dataset import
test = pd.read_csv('/content/UNSW_NB15_testing-set.csv')

# Train DataSet Import
train = pd.read_csv('/content/UNSW_NB15_training-set.csv')

# Finding the Null values
train.isnull().sum()

train.shape

test.isnull().sum()

test.shape

# Removing the index columns
train.drop(['id'], axis=1 ,inplace= True)

test.drop(['id'], axis=1 , inplace = True)

train.describe()

"""Data is clean.No missing Values.

"""

#
train.attack_cat.value_counts().plot.bar()

test.attack_cat.value_counts().plot.bar()

from sklearn import preprocessing
le = preprocessing.LabelEncoder()
train['attack_cat']= le.fit_transform(train['attack_cat'])
train['proto']= le.fit_transform(train['proto'])
train['service']= le.fit_transform(train['service'])
train['state']= le.fit_transform(train['state'])

le = preprocessing.LabelEncoder()
test['attack_cat']= le.fit_transform(test['attack_cat'])
test['proto']= le.fit_transform(test['proto'])
test['service']= le.fit_transform(test['service'])
test['state']= le.fit_transform(test['state'])

train

test

sns.countplot(data = train,x = train['label'],hue = "label")

sns.countplot(data = test,x = test['label'],hue = "label")

train['label'].value_counts()

test['label'].value_counts()

train.attack_cat.value_counts().plot.bar()

test.attack_cat.value_counts().plot.bar()

Data = pd.concat([train,test])

X = Data.drop("label",axis = 1)
Y = Data["label"]

"""Normalizing the data set"""

#  Normalizing the dataset using Standard Scaler
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
Std = scaler.fit_transform(X)
Std

Std.shape

"""**Feature selection using Principle Component Analysis**"""

pca = PCA(n_components= 25)
Std_pca = pca.fit_transform(Std)

Std_pca.shape

"""**Splitting the combined data set into 80% - 20% split**"""

from sklearn.model_selection import train_test_split

X_train,X_test,Y_train,Y_test = train_test_split(Std_pca,Y,test_size=0.20,random_state = 2)

"""**Decision Tree Algotithm**"""

from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score
from sklearn.metrics import classification_report,confusion_matrix
from sklearn import svm

classifier = DecisionTreeClassifier()

import math, time, random, datetime

start_time = time.time()
classifier.fit(X_train,Y_train)
Y_pred = classifier.predict(X_test)
accuracy_score(Y_test,Y_pred)
dt_time = (time.time() - start_time)
print("Execution time: %s" % dt_time)
print('Accuracy:',accuracy_score(Y_test,Y_pred))
print(classification_report(Y_test,Y_pred))

confusion_matrix(Y_test,Y_pred)

"""**Random Forest Algorithm**"""

from sklearn.ensemble import RandomForestClassifier

start_time = time.time()
model = RandomForestClassifier()
model.fit(X_train,Y_train)
pred = model.predict(X_test)
accuracy_score(Y_test,pred)
end_time = time.time()
dt_time = (end_time - start_time)
print("Execution time: %s" % dt_time)
print("Accuracy:",accuracy_score(Y_test,pred))
print(classification_report(Y_test,pred))

print(confusion_matrix(Y_test,pred))

"""**Support Vector Machine Algorithm**"""

start_time = time.time()
Model_1 =svm.SVC()
Model_1.fit(X_train,Y_train)
Prediction = Model_1.predict(X_test) 
end_time = time.time()
dt_time = (end_time - start_time)
print("Execution time: %s" % dt_time)
print("Accuracy:",accuracy_score(Y_test,Prediction))
print(classification_report(Y_test,Prediction))

cm = (confusion_matrix(Y_test,Prediction))
cm

plt.figure(figsize=(5,6))
ax = sns.heatmap(cm/np.sum(cm),annot=True,fmt='.2%', cmap='Blues')
ax.set_title('Confusion Matrix')
ax.set_ylabel('label')
plt.xticks(rotation=45)
plt.yticks(rotation=0)
plt.tight_layout()
plt.show()

"""**Artificial Neural Network**"""

import tensorflow as tf
ann = tf.keras.models.Sequential()

#Adding First Hidden Layer
ann.add(tf.keras.layers.Dense(units=6,activation="relu"))

#Adding Second Hidden Layer
ann.add(tf.keras.layers.Dense(units=6,activation="relu"))

#Adding Output Layer
ann.add(tf.keras.layers.Dense(units=1,activation="sigmoid"))

#Compiling ANN
ann.compile(optimizer="adam",loss="binary_crossentropy",metrics=['accuracy'])

#Fitting ANN
ann.fit(X_train,Y_train,batch_size=32,epochs = 10)

ann.evaluate(X_test,Y_test)

pd = ann.predict(X_test)
pd

y_pred = []
for i in pd:
  if i  > 0.5:
    y_pred.append(1)
  else:
    y_pred.append(0)

print(classification_report(Y_test,y_pred))

"""XGBoost Classifier"""

from xgboost import XGBClassifier

start_time = time.time()
model_1= XGBClassifier()
model_1.fit(X_train, Y_train)
predict= model_1.predict(X_test)
end_time = time.time()
dt_time = (end_time - start_time)
print("Execution time: %s" % dt_time)
print("Accuracy:",accuracy_score(Y_test,predict))
print(classification_report(Y_test,predict))

"""Navie Bayes Classifier"""

from sklearn.naive_bayes import GaussianNB 
start_time = time.time() 
classifier = GaussianNB()  
classifier.fit(X_train, Y_train) 
Y_prediction = classifier.predict(X_test)
end_time = time.time()
dt_time = (end_time - start_time)
print("Execution time: %s" % dt_time)
print("Accuracy:",accuracy_score(Y_test,Y_prediction))
print(classification_report(Y_test,Y_prediction))